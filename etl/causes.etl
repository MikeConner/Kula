# put this at the top of your script
require_relative '../config/environment'

# then declare your Kiba ETL script

#!/usr/bin/env ruby

$:.unshift "#{File.dirname(__FILE__)}/lib"

require 'cause_source'
require 'cause_destination'

#TODO: Get this from Database.yml
PGDevURL = "postgresql://captain:MonkeY1984@kula-rds-dev.cgql7wtq7xwt.us-west-2.rds.amazonaws.com/kula_pg_dev"


config = YAML.load(IO.read('config/database.yml'))
start_time = Time.now


pre_process do

  puts "--------------------------------------------"
  puts "*** START CAUSES REPLICATION #{start_time}***"
end

#
  # Count rows
  # --- for full insert, go by cause_id
  # --- start with limit 10000 and get max cause_id
  # pass in > max_cause_id and get 10000
  # end loop based on rows divided by batch size times.

  # ---- this is for updates
  # order by modified DATE
  # Larger than MOdified date in param
  # store in table last modified DATE
  # Upsert if modified ate passed in or not null (insert otherwise)

  # select rows after or equal to  modified date limit to batch lize
  # select rows after or equal to  modified date limit to batch lize -> get max modified date
     # -> insert in to table as range
  # loop through count/batch_size times -> use last modified date to go to next one (include which means we need upsert )


source CauseSource, config['replica']

#transform FilterMD5

transform do |row|
  print "."
  newrow = row
  newrow[:cause_type] = row[:type]
  
  newrow
end


destination CauseDestination, PGDevURL

post_process do
  end_time = Time.now
  duration_in_minutes = (end_time - start_time)/60
  puts ""
  puts "*** End CAUSES REPLICATION #{end_time}***"
  puts "*** Duration (min): #{duration_in_minutes.round(2)}"
end
